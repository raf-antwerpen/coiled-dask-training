{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing Your Own Python Algorithms\n",
    "\n",
    "## Lab Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = coiled.Cluster(name=\"training-cluster\")\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab - Emergency Services Modeling\n",
    "\n",
    "We'll work on a more complicated simulation-based model to evaluate time-to-response for emergency vehicles in different schemes for Cascadia City.\n",
    "\n",
    "Part of the city is planned as a 16x16 block street grid, and we'd like to look at a few different models where we divide this region into equal-sized zones, and each zone has its own emergency vehicle (which must remain inside that zone).\n",
    "\n",
    "The purpose of our lab is to use Dask to distribute the work, so we'll start with some functions that do most of the calculation work, and focus on running those in the Dask cluster using `Future`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "traffic = np.load('data/traffic.npy')\n",
    "\n",
    "plt.imshow(traffic)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array represents transit time costs (in minutes, under congested conditions) to reach all of the intersections in this 16x16 block grid, based on data from other cities.\n",
    "\n",
    "To find travel time between points for the whole grid -- or for a section -- we'll build an *adjacency matrix* and then use a shortest-path algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_chunk_width = 4 # we'll work with square chunks, so N-S and E-W are both 4\n",
    "\n",
    "def build_adj_matrix(costs):\n",
    "    adj_dim = costs.shape[0] ** 2\n",
    "    adj_matix = np.zeros((adj_dim, adj_dim)) # since every pair of locations gets a cost in the adj matrix\n",
    "    \n",
    "    def linear_loc_for_row_col(r, c):\n",
    "        return r + c*costs.shape[0]\n",
    "    \n",
    "    for i in range(costs.shape[0]):\n",
    "        for j in range(costs.shape[1]):\n",
    "            cost_to_ij = costs[i, j]\n",
    "            dest_loc = linear_loc_for_row_col(i, j)\n",
    "            if i > 0:\n",
    "                adj_matix[linear_loc_for_row_col(i-1, j), dest_loc] = cost_to_ij                \n",
    "            if i < costs.shape[0] - 1:\n",
    "                adj_matix[linear_loc_for_row_col(i+1, j), dest_loc] = cost_to_ij                \n",
    "            if j > 0:\n",
    "                adj_matix[linear_loc_for_row_col(i, j-1), dest_loc] = cost_to_ij                \n",
    "            if j < costs.shape[1] - 1:\n",
    "                adj_matix[linear_loc_for_row_col(i, j+1), dest_loc] = cost_to_ij\n",
    "    return adj_matix\n",
    "\n",
    "demo_adj = build_adj_matrix(traffic[0:city_chunk_width, 0:city_chunk_width])\n",
    "plt.imshow(demo_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a helper from `scipy` to find the shortest path (expressed here as travel time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.csgraph import shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_travel_time_all = shortest_path(demo_adj)\n",
    "plt.imshow(total_travel_time_all)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, suppose there are a fire and a fire truck at particular locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def response_to_random_fire(travel_time_matrix, zone_rows, zone_cols):\n",
    "    fire_x = random.randint(0, zone_cols-1)\n",
    "    fire_y = random.randint(0, zone_rows-1)\n",
    "\n",
    "    firetruck_x = random.randint(0, zone_cols-1)\n",
    "    firetruck_y = random.randint(0, zone_rows-1)\n",
    "\n",
    "    travel_from = firetruck_y + zone_rows*firetruck_x\n",
    "    travel_to = fire_y + zone_rows*fire_x\n",
    "    \n",
    "    return travel_time_matrix[travel_from, travel_to]\n",
    "\n",
    "response_sample = response_to_random_fire(total_travel_time_all, city_chunk_width, city_chunk_width)\n",
    "\n",
    "print(\"Travel time\", response_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to measure response time under various scenarios, including ones where more trucks are available.\n",
    "\n",
    "#### Activity 1: Travel time matrices for all zones\n",
    "\n",
    "Divide the full traffic map (matrix) into 16 subsections similar to the one above, and generate travel time matrices for all of them using Dask.\n",
    "\n",
    "Note: in some scenarios we might use Dask array, but for today's exercise, let's use regular NumPy and focus on parallelizing our work with `Future`.\n",
    "\n",
    "Hint: For dividing the matrix into subsections, adapt this sample code using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12], [13,14,15,16]])\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = []\n",
    "\n",
    "for outer in map(lambda m : np.vsplit(m, 2), np.hsplit(example, 2)):\n",
    "    for inner in outer:\n",
    "        arrays.append(inner)\n",
    "    \n",
    "arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = []\n",
    "\n",
    "for outer in map(lambda m : np.vsplit(m, city_chunk_width), np.hsplit(traffic, city_chunk_width)):\n",
    "    for inner in outer:\n",
    "        zones.append(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_data = client.map(build_adj_matrix, zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_times_futures = client.map(shortest_path, adj_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_times = client.gather(travel_times_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(travel_times[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 2: Emergency response times for all zones\n",
    "\n",
    "Simulate emergency response times for each zone, using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_count = len(zones)\n",
    "\n",
    "sample = client.map(response_to_random_fire, travel_times_futures, \n",
    "                    [city_chunk_width]*zone_count, [city_chunk_width]*zone_count, pure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.gather(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 3: Collect and plot samples for all zones\n",
    "\n",
    "Gather 100 samples for each zone, combine the results, and plot a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample_futures = []\n",
    "for i in range(100):\n",
    "    all_sample_futures.extend( \\\n",
    "        client.map(response_to_random_fire, travel_times_futures, \n",
    "                   [city_chunk_width]*zone_count, [city_chunk_width]*zone_count, pure=False))\n",
    "    \n",
    "plt.hist(client.gather(all_sample_futures), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 4: Compare zone schemes\n",
    "\n",
    "*Bonus*\n",
    "\n",
    "Simulate\n",
    "* the single-zone model with 16 firetrucks uniformly distributed\n",
    "  * this means 1 zone and `city_chunk_width` of 16\n",
    "  * 16 random firetruck locations, so 16 travel times (choose shortest or mean)\n",
    "* 4-zone model (each zone `city_chunk_width` of 8)\n",
    "\n",
    "Compare the response time distributions to the 16-zone model we've done so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
