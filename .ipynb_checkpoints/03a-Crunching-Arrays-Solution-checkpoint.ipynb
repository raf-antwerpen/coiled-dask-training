{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Array Lab Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = coiled.Cluster(name=\"training-cluster\")\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab: Investigating topography\n",
    "\n",
    "*Note: for all of these labs, we'll start with the re-chunked, thinner Zarr version of our data (we won't need the alpha channel we discarded prior to that, and the chunking will be a good starting point.*\n",
    "\n",
    "#### Activity 1: Proper decoding of image data\n",
    "\n",
    "Since human eyes have different sensitivities to red, green, and blue, a grayscale image is usually not encoded in RGB format using the same intensities (pixel values) for all 3 channels. In fact, even averaging across the channels doesn't always get you the right grayscale level.\n",
    "\n",
    "This terrain data was encoded using the \"luminosity\" method, which means our real values are determined by this formula: 0.21 R + 0.72 G + 0.07 B\n",
    "\n",
    "Use that formula to convert the 3-channel data to an elevation map. Then scale the elevations: \n",
    "* reference values for min and max elevation for this map area are 30 feet (min) to 1100 feet (max)\n",
    "* because of how the maps are generated, those reference elevations may not actually exist in this area\n",
    "\n",
    "Let's transform and then find the min/max in our land area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "lab_elevations = da.from_zarr('s3://coiled-training/data/land', chunks=(200, 200, 4), storage_options={\"anon\": True})\n",
    "\n",
    "lab_elevation_map = 0.21 * lab_elevations[:, :, 0] + \\\n",
    "                    0.72 * lab_elevations[:, :, 1] + \\\n",
    "                    0.07 * lab_elevations[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_elevation_map = ((1100-30)/255.0) * lab_elevation_map + 30\n",
    "lab_elevation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_elevation_map.min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_elevation_map.max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 2: Finding least-rugged terrain block\n",
    "\n",
    "Let's repeat our elevation variance investigation. See if you can also determine the coordinates of the \"least-variance\" block programmatically using Dask (not NumPy).\n",
    "\n",
    "Hint: if we want Dask to know the shape of our array after calling `map_blocks`, we have to give that API call some info by using the `chunks=` parameter (since otherwise it has no idea of the shape our `elevation_std` will return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def elevation_std(array_block):\n",
    "    return np.array([[np.std(array_block)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_variance = lab_elevation_map.map_blocks(elevation_std, chunks=(1,1))\n",
    "\n",
    "lab_variance.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gray()\n",
    "\n",
    "plt.imshow(lab_variance.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = lab_variance.argmin().compute()\n",
    "\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(location, lab_variance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_variance[2,5].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 3: Zoom in for smoother land\n",
    "\n",
    "*Bonus Project*\n",
    "\n",
    "Now that we know roughly where to search, let's zoom in on that specific block in the elevation map. It's 200x200 units, and those units are pretty big. Let's further divide that block into 10x10 areas and look again. Hint: find the original block and `rechunk`\n",
    "\n",
    "For more information on how the elevation changes, try calculating `min` or `max` for the chunks and then generating a report of changes with `diff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_res = lab_elevation_map.blocks[2,5].rechunk((10,10))\n",
    "hi_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hi_res.map_blocks(elevation_std, chunks=(1,1)).compute())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[[3,4]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_min_max(block):\n",
    "    return np.array([[[block.min()]], [[block.max()]]])\n",
    "\n",
    "min_max = hi_res.map_blocks(block_min_max, chunks=(2,1,1))\n",
    "\n",
    "min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(min_max[0].compute()) #mins\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(da.diff(min_max[0], axis=0).compute()) #min diffs\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(min_max[1].compute()) #max\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(da.diff(min_max[1], axis=0).compute()) #max diffs\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
